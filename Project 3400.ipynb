{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d6c046-46e3-42b8-9f85-42e054bae73e",
   "metadata": {},
   "source": [
    "## COMP 3400 MINI PROJECT: PREDICTING PRECIPITATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa446885-cb9e-4293-ba46-724358704325",
   "metadata": {},
   "source": [
    "#### Name: Kay-Salami Motolani Karima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3c305-bfdc-422c-adbc-0bfff115e471",
   "metadata": {},
   "source": [
    "#### Student ID: 20215668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff9b2b9-01ef-4f94-a78d-34aa7eeca202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (13843, 9)\n",
      "Basic statistics of the data:\n",
      "        cloud_cover      sunshine  global_radiation      max_temp  \\\n",
      "count  13843.00000  13843.000000      13843.000000  13843.000000   \n",
      "mean       5.32818      4.262609        114.529148     14.951911   \n",
      "std        2.03417      3.987488         87.758136      6.510220   \n",
      "min        0.00000      0.000000         12.000000     -6.200000   \n",
      "25%        4.00000      0.400000         39.000000     10.200000   \n",
      "50%        6.00000      3.400000         89.000000     14.400000   \n",
      "75%        7.00000      7.100000        180.000000     19.700000   \n",
      "max        9.00000     15.700000        352.000000     37.900000   \n",
      "\n",
      "          mean_temp      min_temp  precipitation       pressure    snow_depth  \n",
      "count  13843.000000  13843.000000   13843.000000   13843.000000  13843.000000  \n",
      "mean      11.085408      7.212302       1.667493  101538.493101      0.037853  \n",
      "std        5.700936      5.319409       3.733947    1066.084413      0.545712  \n",
      "min       -7.600000    -11.800000       0.000000   95960.000000      0.000000  \n",
      "25%        6.800000      3.200000       0.000000  100900.000000      0.000000  \n",
      "50%       10.800000      7.300000       0.000000  101630.000000      0.000000  \n",
      "75%       15.550000     11.400000       1.600000  102260.000000      0.000000  \n",
      "max       29.000000     22.300000      61.800000  104430.000000     22.000000  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"//Users//motolanikay-salami//Desktop//london_weather.csv\")\n",
    "\n",
    "# Remove the 'date' column as it's not needed for modeling\n",
    "df = df.drop(columns=['date'])\n",
    "\n",
    "# Drop rows with missing values to avoid errors in calculations\n",
    "df = df.dropna()\n",
    "\n",
    "print(\"Dataset loaded with shape:\", df.shape)\n",
    "print(\"Basic statistics of the data:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0204394-4545-4ab2-9f83-8897a1769790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = df.drop(columns=['precipitation'])\n",
    "y = df['precipitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b32ee07b-e94f-4567-b582-e14ea80f6edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 11074 samples\n",
      "Testing set size: 2769 samples\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(0.8 * len(df))\n",
    "\n",
    "X_train = X.iloc[:split_idx]\n",
    "X_test = X.iloc[split_idx:]\n",
    "\n",
    "y_train = y.iloc[:split_idx]\n",
    "y_test = y.iloc[split_idx:]\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0], \"samples\")\n",
    "print(\"Testing set size:\", X_test.shape[0], \"samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e23396d3-f202-4598-a1e5-b7991a36c0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Linear Regression Model\n",
      "R² score on test set: 0.1306\n"
     ]
    }
   ],
   "source": [
    "# Add bias term (column of ones) to feature matrices\n",
    "X_train_b = np.c_[np.ones((X_train.shape[0], 1)), X_train.values]\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test.values]\n",
    "\n",
    "# Convert target vector to 2D array for calculations\n",
    "y_train_np = y_train.values.reshape(-1, 1)\n",
    "\n",
    "# Calculate theta (weights) using normal equation\n",
    "theta = np.linalg.pinv(X_train_b.T @ X_train_b) @ X_train_b.T @ y_train_np\n",
    "\n",
    "# Make predictions on test set\n",
    "y_pred_baseline = (X_test_b @ theta).flatten()\n",
    "\n",
    "# Calculate R² score manually\n",
    "ss_res = np.sum((y_test.values - y_pred_baseline) ** 2)\n",
    "ss_tot = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "baseline_r2 = 1 - ss_res / ss_tot\n",
    "\n",
    "print(\"\\nBaseline Linear Regression Model\")\n",
    "print(\"R² score on test set:\", round(baseline_r2, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cb9d00a-442f-46c9-8385-ec725a0122ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying data transformations to improve model:\n",
      "Standardization R²: 0.1306 | Improvement: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize best score and current data for next steps\n",
    "best_score = baseline_r2\n",
    "current_X_train = X_train.copy()\n",
    "current_X_test = X_test.copy()\n",
    "\n",
    "# List to keep track of model performances\n",
    "results_log = [(\"Baseline\", baseline_r2)]\n",
    "\n",
    "print(\"\\nTrying data transformations to improve model:\")\n",
    "\n",
    "# Attempt 1: Standardization\n",
    "mean_train = current_X_train.mean()\n",
    "std_train = current_X_train.std()\n",
    "\n",
    "X_train_std = (current_X_train - mean_train) / std_train\n",
    "X_test_std = (current_X_test - mean_train) / std_train\n",
    "\n",
    "Xb_train_std = np.c_[np.ones((X_train_std.shape[0], 1)), X_train_std.values]\n",
    "Xb_test_std = np.c_[np.ones((X_test_std.shape[0], 1)), X_test_std.values]\n",
    "\n",
    "theta_std = np.linalg.pinv(Xb_train_std.T @ Xb_train_std) @ Xb_train_std.T @ y_train.values.reshape(-1, 1)\n",
    "y_pred_std = (Xb_test_std @ theta_std).flatten()\n",
    "\n",
    "ss_res_std = np.sum((y_test.values - y_pred_std) ** 2)\n",
    "ss_tot_std = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "r2_std = 1 - ss_res_std / ss_tot_std\n",
    "\n",
    "print(\"Standardization R²:\", round(r2_std, 4), \"| Improvement:\", r2_std > best_score)\n",
    "results_log.append((\"Standardization\", r2_std))\n",
    "\n",
    "if r2_std > best_score:\n",
    "    best_score = r2_std\n",
    "    current_X_train = X_train_std\n",
    "    current_X_test = X_test_std\n",
    "else:\n",
    "    # Attempt 2: Min-Max Normalization\n",
    "    min_train = current_X_train.min()\n",
    "    max_train = current_X_train.max()\n",
    "\n",
    "    X_train_norm = (current_X_train - min_train) / (max_train - min_train)\n",
    "    X_test_norm = (current_X_test - min_train) / (max_train - min_train)\n",
    "\n",
    "    Xb_train_norm = np.c_[np.ones((X_train_norm.shape[0], 1)), X_train_norm.values]\n",
    "    Xb_test_norm = np.c_[np.ones((X_test_norm.shape[0], 1)), X_test_norm.values]\n",
    "\n",
    "    theta_norm = np.linalg.pinv(Xb_train_norm.T @ Xb_train_norm) @ Xb_train_norm.T @ y_train.values.reshape(-1, 1)\n",
    "    y_pred_norm = (Xb_test_norm @ theta_norm).flatten()\n",
    "\n",
    "    ss_res_norm = np.sum((y_test.values - y_pred_norm) ** 2)\n",
    "    ss_tot_norm = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "    r2_norm = 1 - ss_res_norm / ss_tot_norm\n",
    "\n",
    "    print(\"Normalization R²:\", round(r2_norm, 4), \"| Improvement:\", r2_norm > best_score)\n",
    "    results_log.append((\"Normalization\", r2_norm))\n",
    "\n",
    "    if r2_norm > best_score:\n",
    "        best_score = r2_norm\n",
    "        current_X_train = X_train_norm\n",
    "        current_X_test = X_test_norm\n",
    "    else:\n",
    "        # Attempt 3: Max Abs Scaling\n",
    "        max_abs_train = current_X_train.abs().max()\n",
    "\n",
    "        X_train_maxabs = current_X_train / max_abs_train\n",
    "        X_test_maxabs = current_X_test / max_abs_train\n",
    "\n",
    "        Xb_train_maxabs = np.c_[np.ones((X_train_maxabs.shape[0], 1)), X_train_maxabs.values]\n",
    "        Xb_test_maxabs = np.c_[np.ones((X_test_maxabs.shape[0], 1)), X_test_maxabs.values]\n",
    "\n",
    "        theta_maxabs = np.linalg.pinv(Xb_train_maxabs.T @ Xb_train_maxabs) @ Xb_train_maxabs.T @ y_train.values.reshape(-1, 1)\n",
    "        y_pred_maxabs = (Xb_test_maxabs @ theta_maxabs).flatten()\n",
    "\n",
    "        ss_res_maxabs = np.sum((y_test.values - y_pred_maxabs) ** 2)\n",
    "        ss_tot_maxabs = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "        r2_maxabs = 1 - ss_res_maxabs / ss_tot_maxabs\n",
    "\n",
    "        print(\"Max Abs Scaling R²:\", round(r2_maxabs, 4), \"| Improvement:\", r2_maxabs > best_score)\n",
    "        results_log.append((\"Max Abs Scaling\", r2_maxabs))\n",
    "\n",
    "        if r2_maxabs > best_score:\n",
    "            best_score = r2_maxabs\n",
    "            current_X_train = X_train_maxabs\n",
    "            current_X_test = X_test_maxabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6dd3dff-d3a7-4fe1-aba9-bd4885a0c3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying data transformations to improve model:\n",
      "Standardization R²: 0.1306 | Improvement: True\n"
     ]
    }
   ],
   "source": [
    "# Initialize best score and current data for next steps\n",
    "best_score = baseline_r2\n",
    "current_X_train = X_train.copy()\n",
    "current_X_test = X_test.copy()\n",
    "\n",
    "# List to keep track of model performances\n",
    "results_log = [(\"Baseline\", baseline_r2)]\n",
    "\n",
    "print(\"\\nTrying data transformations to improve model:\")\n",
    "\n",
    "# Attempt 1: Standardization\n",
    "mean_train = current_X_train.mean()\n",
    "std_train = current_X_train.std()\n",
    "\n",
    "X_train_std = (current_X_train - mean_train) / std_train\n",
    "X_test_std = (current_X_test - mean_train) / std_train\n",
    "\n",
    "Xb_train_std = np.c_[np.ones((X_train_std.shape[0], 1)), X_train_std.values]\n",
    "Xb_test_std = np.c_[np.ones((X_test_std.shape[0], 1)), X_test_std.values]\n",
    "\n",
    "theta_std = np.linalg.pinv(Xb_train_std.T @ Xb_train_std) @ Xb_train_std.T @ y_train.values.reshape(-1, 1)\n",
    "y_pred_std = (Xb_test_std @ theta_std).flatten()\n",
    "\n",
    "ss_res_std = np.sum((y_test.values - y_pred_std) ** 2)\n",
    "ss_tot_std = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "r2_std = 1 - ss_res_std / ss_tot_std\n",
    "\n",
    "print(\"Standardization R²:\", round(r2_std, 4), \"| Improvement:\", r2_std > best_score)\n",
    "results_log.append((\"Standardization\", r2_std))\n",
    "\n",
    "if r2_std > best_score:\n",
    "    best_score = r2_std\n",
    "    current_X_train = X_train_std\n",
    "    current_X_test = X_test_std\n",
    "else:\n",
    "    # Attempt 2: Min-Max Normalization\n",
    "    min_train = current_X_train.min()\n",
    "    max_train = current_X_train.max()\n",
    "\n",
    "    X_train_norm = (current_X_train - min_train) / (max_train - min_train)\n",
    "    X_test_norm = (current_X_test - min_train) / (max_train - min_train)\n",
    "\n",
    "    Xb_train_norm = np.c_[np.ones((X_train_norm.shape[0], 1)), X_train_norm.values]\n",
    "    Xb_test_norm = np.c_[np.ones((X_test_norm.shape[0], 1)), X_test_norm.values]\n",
    "\n",
    "    theta_norm = np.linalg.pinv(Xb_train_norm.T @ Xb_train_norm) @ Xb_train_norm.T @ y_train.values.reshape(-1, 1)\n",
    "    y_pred_norm = (Xb_test_norm @ theta_norm).flatten()\n",
    "\n",
    "    ss_res_norm = np.sum((y_test.values - y_pred_norm) ** 2)\n",
    "    ss_tot_norm = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "    r2_norm = 1 - ss_res_norm / ss_tot_norm\n",
    "\n",
    "    print(\"Normalization R²:\", round(r2_norm, 4), \"| Improvement:\", r2_norm > best_score)\n",
    "    results_log.append((\"Normalization\", r2_norm))\n",
    "\n",
    "    if r2_norm > best_score:\n",
    "        best_score = r2_norm\n",
    "        current_X_train = X_train_norm\n",
    "        current_X_test = X_test_norm\n",
    "    else:\n",
    "        # Attempt 3: Max Abs Scaling\n",
    "        max_abs_train = current_X_train.abs().max()\n",
    "\n",
    "        X_train_maxabs = current_X_train / max_abs_train\n",
    "        X_test_maxabs = current_X_test / max_abs_train\n",
    "\n",
    "        Xb_train_maxabs = np.c_[np.ones((X_train_maxabs.shape[0], 1)), X_train_maxabs.values]\n",
    "        Xb_test_maxabs = np.c_[np.ones((X_test_maxabs.shape[0], 1)), X_test_maxabs.values]\n",
    "\n",
    "        theta_maxabs = np.linalg.pinv(Xb_train_maxabs.T @ Xb_train_maxabs) @ Xb_train_maxabs.T @ y_train.values.reshape(-1, 1)\n",
    "        y_pred_maxabs = (Xb_test_maxabs @ theta_maxabs).flatten()\n",
    "\n",
    "        ss_res_maxabs = np.sum((y_test.values - y_pred_maxabs) ** 2)\n",
    "        ss_tot_maxabs = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "        r2_maxabs = 1 - ss_res_maxabs / ss_tot_maxabs\n",
    "\n",
    "        print(\"Max Abs Scaling R²:\", round(r2_maxabs, 4), \"| Improvement:\", r2_maxabs > best_score)\n",
    "        results_log.append((\"Max Abs Scaling\", r2_maxabs))\n",
    "\n",
    "        if r2_maxabs > best_score:\n",
    "            best_score = r2_maxabs\n",
    "            current_X_train = X_train_maxabs\n",
    "            current_X_test = X_test_maxabs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ed52919-c597-40ec-99ab-a2de43953144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting feature selection by correlation thresholds:\n",
      "Threshold 0.95 | Dropped 1 features | R²: 0.132 | Improvement: True\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection based on Correlation\n",
    "print(\"\\nStarting feature selection by correlation thresholds:\")\n",
    "\n",
    "for threshold in [0.95, 0.90, 0.85]:\n",
    "    corr_matrix = current_X_train.corr().abs()\n",
    "    upper_tri = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    high_corr = (corr_matrix.values * upper_tri) > threshold\n",
    "\n",
    "    drop_indices = np.unique(np.where(high_corr)[1])\n",
    "    drop_columns = corr_matrix.columns[drop_indices]\n",
    "\n",
    "    X_train_fs = current_X_train.drop(columns=drop_columns)\n",
    "    X_test_fs = current_X_test.drop(columns=drop_columns)\n",
    "\n",
    "    Xb_train_fs = np.c_[np.ones((X_train_fs.shape[0], 1)), X_train_fs.values]\n",
    "    Xb_test_fs = np.c_[np.ones((X_test_fs.shape[0], 1)), X_test_fs.values]\n",
    "\n",
    "    theta_fs = np.linalg.pinv(Xb_train_fs.T @ Xb_train_fs) @ Xb_train_fs.T @ y_train.values.reshape(-1, 1)\n",
    "    y_pred_fs = (Xb_test_fs @ theta_fs).flatten()\n",
    "\n",
    "    ss_res_fs = np.sum((y_test.values - y_pred_fs) ** 2)\n",
    "    ss_tot_fs = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "    r2_fs = 1 - ss_res_fs / ss_tot_fs\n",
    "\n",
    "    print(f\"Threshold {threshold} | Dropped {len(drop_columns)} features | R²: {round(r2_fs, 4)} | Improvement: {r2_fs > best_score}\")\n",
    "    results_log.append((f\"Feature Selection thresh={threshold}\", r2_fs))\n",
    "\n",
    "    if r2_fs > best_score:\n",
    "        best_score = r2_fs\n",
    "        current_X_train = X_train_fs\n",
    "        current_X_test = X_test_fs\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e20e9d1-d0b4-4110-89c6-e76788ed660f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trying outlier removal to improve model:\n",
      "Z-Score Threshold 3 | Min Features 1 | Removed 147 rows | R²: 0.1324 | Improvement: True\n"
     ]
    }
   ],
   "source": [
    "# Outlier Detection\n",
    "print(\"\\nTrying outlier removal to improve model:\")\n",
    "\n",
    "for z_threshold, min_features in [(3, 1), (3, 2), (2.5, 1)]:\n",
    "    z_scores = (current_X_train - current_X_train.mean()) / current_X_train.std()\n",
    "    outlier_flags = (np.abs(z_scores) > z_threshold).sum(axis=1) >= min_features\n",
    "\n",
    "    X_train_clean = current_X_train[~outlier_flags]\n",
    "    y_train_clean = y_train[~outlier_flags]\n",
    "\n",
    "    Xb_train_clean = np.c_[np.ones((X_train_clean.shape[0], 1)), X_train_clean.values]\n",
    "    Xb_test_current = np.c_[np.ones((current_X_test.shape[0], 1)), current_X_test.values]\n",
    "\n",
    "    theta_clean = np.linalg.pinv(Xb_train_clean.T @ Xb_train_clean) @ Xb_train_clean.T @ y_train_clean.values.reshape(-1, 1)\n",
    "    y_pred_clean = (Xb_test_current @ theta_clean).flatten()\n",
    "\n",
    "    ss_res_clean = np.sum((y_test.values - y_pred_clean) ** 2)\n",
    "    ss_tot_clean = np.sum((y_test.values - np.mean(y_test.values)) ** 2)\n",
    "    r2_clean = 1 - ss_res_clean / ss_tot_clean\n",
    "\n",
    "    print(\"Z-Score Threshold\", z_threshold, \"| Min Features\", min_features, \"| Removed\", outlier_flags.sum(), \"rows | R²:\", round(r2_clean, 4), \"| Improvement:\", r2_clean > best_score)\n",
    "    results_log.append((\"Outlier removal z=\" + str(z_threshold) + \", m=\" + str(min_features), r2_clean))\n",
    "\n",
    "    if r2_clean > best_score:\n",
    "        best_score = r2_clean\n",
    "        current_X_train = X_train_clean\n",
    "        y_train = y_train_clean\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6804c80-8ac1-45cd-a4d6-19f847b9ad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of model improvements:\n",
      "Baseline R²: 0.1306\n",
      "Best R² after transformations and feature engineering: 0.1324\n",
      "\n",
      "Detailed steps and scores:\n",
      "- Baseline: R² = 0.1306\n",
      "- Standardization: R² = 0.1306\n",
      "- Feature Selection thresh=0.95: R² = 0.132\n",
      "- Outlier removal z=3, m=1: R² = 0.1324\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary of model improvements:\")\n",
    "print(\"Baseline R²:\", round(baseline_r2, 4))\n",
    "print(\"Best R² after transformations and feature engineering:\", round(best_score, 4))\n",
    "\n",
    "print(\"\\nDetailed steps and scores:\")\n",
    "for step_name, score_val in results_log:\n",
    "    print(\"-\", step_name + \":\", \"R² =\", round(score_val, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a23eb2-4f1d-4efc-9152-209ced4aac26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec9a29-cead-4971-a89d-d578b6d755f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da37435-5451-44a0-b7f2-6f5b0cfe685f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579452cf-fa6e-4d2e-99b2-efda89eeee13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc86256-5b9e-40df-95fe-cd83904850e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815309d-8407-480a-aba2-d0e8e5edbe16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31c5cd-eb5a-4db2-beb7-00d1d3cf6657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b35b7c1-23f4-453a-961c-6461f67ff5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed22a3df-a4d5-451d-a0b2-d102492fdbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6f7c5-28bb-4a73-a5d3-2a2d25f97d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254630ee-aa13-4ff2-ac15-bee076ba8ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30a13ab-a11b-438e-b31e-5d6f46bce2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632fc55d-f67f-4fe7-9f14-9dc65f4d8e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
